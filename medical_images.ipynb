{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load your dataset (e.g., from a folder structure)\n",
    "def load_images_and_labels(image_dir, img_size, categories):\n",
    "    images, labels = [], []\n",
    "    for category in categories:\n",
    "        path = os.path.join(image_dir, category)\n",
    "        class_num = categories.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
    "                img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "                images.append(img_array)\n",
    "                labels.append(class_num)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Define the categories based on HAM10000 dataset (7 disease categories)\n",
    "categories = ['nv', 'mel', 'bkl', 'bcc', 'akiec', 'vasc', 'df']\n",
    "\n",
    "# Load images and labels\n",
    "IMG_SIZE = 128\n",
    "image_dir = 'path_to_your_HAM10000_data'\n",
    "X, y = load_images_and_labels(image_dir, IMG_SIZE, categories)\n",
    "\n",
    "# Normalize and preprocess the data\n",
    "X = X / 255.0\n",
    "y = to_categorical(y, num_classes=len(categories))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy', \n",
    "                           tf.keras.metrics.AUC(name='auc'), \n",
    "                           tf.keras.metrics.Precision(name='precision'), \n",
    "                           tf.keras.metrics.Recall(name='recall')])\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_model((IMG_SIZE, IMG_SIZE, 3), len(categories))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    epochs=30, \n",
    "                    validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, average_precision_score\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_true, y_pred_classes, target_names=categories)\n",
    "print(report)\n",
    "\n",
    "# Compute F1 Score\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Compute mean Average Precision (mAP)\n",
    "map_score = average_precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Mean Average Precision (mAP): {map_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy and loss\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
